{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Stage directions: basic features\n",
    "\n",
    "This notebook contains:\n",
    "\n",
    "* directions extraction\n",
    "* basic values calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n",
    "<span style=\"font-size:larger;color:blue;\">Run this before everything else!</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "import os\n",
    "from lxml import etree\n",
    "import re\n",
    "import pandas as pd\n",
    "from pymystem3 import Mystem\n",
    "\n",
    "\n",
    "# we need this namespaces parameter to search in TEI-encoded files correctly\n",
    "tei_ns = {'tei': 'http://www.tei-c.org/ns/1.0'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation\n",
    "\n",
    "### Data\n",
    "I used [RusDraCor](https://github.com/dracor-org/rusdracor) as of 8th February, 2018. More precise data on the corpus is below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpus_path = \"..\" + os.sep + \"RusDraCor\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Play class\n",
    "I want to create a table with information on the plays we research, so it will be much easier to have a separate ```Play``` class with all the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Play:\n",
    "    def __init__(self, path, author, title, year_written, year_published, amount_of_directions, amount_of_acts):\n",
    "        self.path = path\n",
    "        self.author = author\n",
    "        self.title = title\n",
    "        self.year_written = year_written\n",
    "        self.year_published = year_published\n",
    "        self.amount_of_directions = amount_of_directions\n",
    "        self.amount_of_acts = amount_of_acts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extraction\n",
    "\n",
    "### Play information\n",
    "The majority of information pieces can be extracted from the ```html <teiHeader></teiHeader>``` in XML itself. Each act is wrapped in ```<div type=\"act\">```, so counting the acts also isn't much of a problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_play_data(play_path):\n",
    "    reg_space = re.compile(\"\\s{2,}\")\n",
    "    root = etree.parse(play_path)\n",
    "    title = root.find(\".//tei:titleStmt/tei:title\", tei_ns).text\n",
    "    title = reg_space.sub(\" \", title)\n",
    "    author = root.find(\".//tei:titleStmt/tei:author\", tei_ns).text\n",
    "    try:\n",
    "        written_str = root.find(\".//tei:sourceDesc/tei:bibl/tei:bibl/tei:date[@type=\\\"written\\\"]\", tei_ns).attrib[\"when\"]\n",
    "        year_written = int(written_str)\n",
    "    except:\n",
    "        year_written = -1\n",
    "    try:\n",
    "        published_str = root.find(\".//tei:sourceDesc/tei:bibl/tei:bibl/tei:date[@type=\\\"print\\\"]\", tei_ns).attrib[\"when\"]\n",
    "        year_published = int(published_str)\n",
    "    except:\n",
    "        year_published = -1\n",
    "    acts = len(root.findall(\".//tei:text/tei:body/tei:div[@type=\\\"act\\\"]\", tei_ns))\n",
    "    return author, title, year_written, year_published, acts    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Directions\n",
    "Basically, all the directions are wrapped by the ```<stage></stage>``` tag, so we can just use regex. The only problem with this approach is that sometimes directions are on separate lines, and many spaces and tabs may occur in between two words â€” and this can also be fixed with the help of regex. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_directions(play_path):\n",
    "    reg_space = re.compile(\"\\s{2,}\")\n",
    "    root = etree.parse(play_path)\n",
    "    directions_tags = root.findall(\".//tei:stage\", tei_ns)\n",
    "    directions_text = []\n",
    "    for direction in directions_tags:\n",
    "        try:\n",
    "            text = direction.text\n",
    "            text = reg_space.sub(\" \", text)\n",
    "            text = text.replace(\"\\xa0\", \" \")\n",
    "            text = text.strip(\"\\(\\) \\.\")\n",
    "            text = text.lower()\n",
    "            directions_text.append(text)\n",
    "        except:\n",
    "            pass\n",
    "    return directions_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putting it all together\n",
    "\n",
    "### Saving the data\n",
    "The following is being done in order to save the extraced directions just in case (and not to extract them from the play every time we need them)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# some basic stuff we need in order to save everything properly\n",
    "directions_path = \"..\" + os.sep + \"data\"\n",
    "if not os.path.exists(directions_path):\n",
    "    os.mkdirs(directions_path)\n",
    "\n",
    "all_directions_file = directions_path + os.sep + \"all_directions.txt\"\n",
    "if not os.path.exists(all_directions_file):\n",
    "    f = open(all_directions_file, \"w\", encoding=\"utf-8\")\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_directions(play_name, directions, option):\n",
    "    if option == \"sep\":\n",
    "        directions_file = directions_path + os.sep + play_name.replace(\"xml\", \"txt\")\n",
    "        with open(directions_file, \"w\", encoding=\"utf-8\") as directions_save:\n",
    "            directions_save.write(\"\\n\".join(directions))\n",
    "    elif option == \"all\":\n",
    "        with open(all_directions_file, \"a\", encoding=\"utf-8\") as all_directions_save:\n",
    "            all_directions_save.write(\"\\n\".join(directions) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working with the corpus\n",
    "\n",
    "Now, we traverse all the plays in the ```corpus_folder``` and do the following: \n",
    "* extract all the directions and save them: \n",
    "    * in a ```directions_list``` variable,\n",
    "    * in a separate file,\n",
    "    * in a file that contains all the directions\n",
    "* extract information about a play and save it into ```play_list``` (to convert it into a Pandas dataframe later)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# this is required because I'm using a Mac, which sometimes creates system folders like .DS_Store;\n",
    "# in any other cases -- never mind\n",
    "play_files = [item for item in os.listdir(corpus_path) if item.endswith(\".xml\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 plays were dropped; they are:\n",
      "- sukhovo-kobylin-smert-tarelkina.xml\n",
      "- shakhovskoy-ne-lubo-ne-slushai.xml\n",
      "- shakhovskoy-pustodomy.xml\n",
      "- lomonosov-tamira-i-selim.xml\n",
      "- naydyonov-deti-vanjushina.xml\n",
      "- plavilshchikov-sgovor-kutejkina.xml\n",
      "- shakhovskoy-svoya-semya.xml\n",
      "- turgenev-razgovor-na-bolshoj-doroge.xml\n",
      "- prutkov-spor-drevnih-grecheskih-filosofov-ob-izjaschnom.xml\n",
      "- shakhovskoy-urok-koketkam.xml\n",
      "- krylov-urok-dochkam.xml\n",
      "- krylov-amerikantsy.xml\n"
     ]
    }
   ],
   "source": [
    "directions_list = []\n",
    "play_list = []\n",
    "id_list = []\n",
    "\n",
    "i = 0\n",
    "dropped_list = []\n",
    "for play in play_files:\n",
    "    play_path = corpus_path + os.sep + play\n",
    "    \n",
    "    st_dirs = get_directions(play_path)\n",
    "    author, title, year_written, year_published, acts = get_play_data(play_path)\n",
    "    play_info = {\"Path\": play_path, \n",
    "            \"Author\": author, \n",
    "            \"Title\": title, \n",
    "            \"Written\": year_written, \n",
    "            \"Published\": year_published, \n",
    "            \"Amount of directions\": len(st_dirs), \n",
    "            \"Amount of acts\": acts if acts!=0 else 1}\n",
    "    \n",
    "    if (play_info[\"Written\"] != -1) and (play_info[\"Published\"] != -1):\n",
    "        # directions\n",
    "        directions_list.append(st_dirs)\n",
    "        save_directions(play, st_dirs, option=\"sep\")\n",
    "        save_directions(play, st_dirs, option=\"all\")\n",
    "        \n",
    "        # add information about a play\n",
    "        play_list.append(play_info)\n",
    "        id_list.append(i)\n",
    "        i += 1\n",
    "    else:\n",
    "        dropped_list.append(play)\n",
    "\n",
    "print(\"{} plays were dropped; they are:\\n- {}\".format(len(dropped_list), \"\\n- \".join(dropped_list)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Corrections\n",
    "Note that the first ```if``` statement in the ```for``` loop removes all the plays where __it is not clear when the play was written and/or published__.\n",
    "\n",
    "Furthermore, if there were no ```<div type=\"act\">```, it means that __there is only one act in the play (not zero)__. I corrected it while creating ```play_info```.\n",
    "\n",
    "### Data frame\n",
    "\n",
    "Now, we create a Pandas data frame with all the information about the plays. We'll use simple integer index (```ind_list```) to refer to rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "play_df = pd.DataFrame(play_list, index=id_list)\n",
    "play_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple numbers\n",
    "We will calculate:\n",
    "\n",
    "* word count,\n",
    "* amounts of the following parts-of-speech:\n",
    "    - nouns,\n",
    "    - adjectives,\n",
    "    - verbs,\n",
    "    - adverbs,\n",
    "    - interjections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m = Mystem()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
